import streamlit as st
import pandas as pd
import re
import time
import duckdb as db
from typing import List, Tuple, Dict
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import plotly.express as px

st.set_page_config(page_title="à¹à¸”à¸Šà¸šà¸­à¸£à¹Œà¸”à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸ªà¸¶à¸", layout="wide")
st.title("ğŸ” à¹à¸”à¸Šà¸šà¸­à¸£à¹Œà¸”à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡ (à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¹€à¸«à¹‡à¸™ YouTube)")

# === à¸„à¸¥à¸²à¸ªà¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸ªà¸¶à¸ ===
class BatchSentimentAnalyzer:
    def __init__(self, model_name: str, batch_size: int = 32):
        self.model_name = model_name
        self.batch_size = batch_size
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)
        self.labels_map = {0: "à¹€à¸Šà¸´à¸‡à¸¥à¸š", 1: "à¹€à¸›à¹‡à¸™à¸à¸¥à¸²à¸‡", 2: "à¹€à¸Šà¸´à¸‡à¸šà¸§à¸"}

    def preprocess_text(self, text: str) -> str:
        if pd.isna(text) or not isinstance(text, str):
            return ""
        return re.sub(r'\s+', ' ', text.strip())[:512]

    def predict_batch(self, texts: List[str]) -> List[Tuple[str, float]]:
        clean_texts = [self.preprocess_text(text) for text in texts]
        inputs = self.tokenizer(clean_texts, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs = self.model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=1)
            preds = torch.argmax(probs, dim=1)
            confidences = torch.max(probs, dim=1)[0]
        return [(self.labels_map[p.item()], c.item()) for p, c in zip(preds, confidences)]

    def analyze_sentiments(self, df: pd.DataFrame, text_col: str) -> pd.DataFrame:
        texts = df[text_col].tolist()
        sentiments, confidences = [], []
        progress_bar = st.progress(0)
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i:i + self.batch_size]
            batch_results = self.predict_batch(batch)
            for s, c in batch_results:
                sentiments.append(s)
                confidences.append(c)
            progress_bar.progress((i + self.batch_size) / len(texts))
        progress_bar.empty()
        df = df.copy()
        df["sentiment"] = sentiments
        df["confidence"] = confidences
        return df

# âœ… à¹ƒà¸Šà¹‰ cache à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸à¸±à¸šà¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™
@st.cache_resource
def load_analyzer(model_name: str, batch_size: int = 32):
    return BatchSentimentAnalyzer(model_name, batch_size)

@st.cache_data
def load_data(db_path: str, table: str) -> pd.DataFrame:
    try:
        con = db.connect(db_path)
        df = con.execute(f"SELECT comment_text_original AS comment FROM {table} LIMIT 1000;").fetchdf()
        con.close()
        return df
    except Exception as e:
        st.error(f"âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸”à¹‰: {e}")
        return pd.DataFrame()

def main():
    st.sidebar.header("âš™ï¸ à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²")
    db_path = st.sidebar.text_input("ğŸ“‚ à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥", value="./comment.duckdb")
    table_name = st.sidebar.text_input("ğŸ—ƒï¸ à¸Šà¸·à¹ˆà¸­à¸•à¸²à¸£à¸²à¸‡", value="yt_comment_full")
    batch_size = st.sidebar.slider("ğŸ“¦ Batch Size", 8, 64, 32)
    model_name = st.sidebar.selectbox("ğŸ¤– à¹€à¸¥à¸·à¸­à¸à¹‚à¸¡à¹€à¸”à¸¥", [
        "airesearch/wangchanberta-base-wiki", 
        "cardiffnlp/twitter-roberta-base-sentiment-latest"
    ])

    df = load_data(db_path, table_name)

    if df.empty:
        st.warning("à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
        return

    st.success(f"âœ… à¹‚à¸«à¸¥à¸” {len(df)} à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¹€à¸«à¹‡à¸™à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")

    if st.button("ğŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ"):
        analyzer = load_analyzer(model_name, batch_size)
        with st.spinner("ğŸ” à¸à¸³à¸¥à¸±à¸‡à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ..."):
            df = analyzer.analyze_sentiments(df, "comment")

        st.session_state["df"] = df
        st.session_state["done"] = True

    if st.session_state.get("done", False):
        df = st.session_state["df"]
        st.subheader("ğŸ“Š à¸œà¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ")
        st.dataframe(df.head(20))

        fig = px.histogram(df, x="sentiment", color="sentiment", title="à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸„à¸´à¸”à¹€à¸«à¹‡à¸™")
        st.plotly_chart(fig)

        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("â¬‡ï¸ à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ", csv, "sentiment_results.csv", "text/csv")

if __name__ == "__main__":
    main()
