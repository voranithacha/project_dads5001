import streamlit as st
import pandas as pd
import plotly.express as px
import torch
import duckdb as db
import re
import time
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import List, Tuple, Dict

st.set_page_config(page_title="‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", layout="wide")
st.title("üîç ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô YouTube")

# ==== ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ cache ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß ====
@st.cache_resource(show_spinner=True)
def load_model(model_name: str):
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)
    return tokenizer, model

# ==== ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DuckDB ====
@st.cache_data
def load_data(db_path: str, table_name: str) -> pd.DataFrame:
    try:
        con = db.connect(db_path)
        query = f"SELECT comment_text_original as comment FROM {table_name} LIMIT 1000;"
        df = con.execute(query).fetchdf()
        con.close()
        return df
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DuckDB ‡πÑ‡∏î‡πâ: {e}")
        return pd.DataFrame()

# ==== ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏ö‡∏ö Batch ====
def predict_sentiments(df: pd.DataFrame, tokenizer, model, batch_size: int = 32) -> pd.DataFrame:
    labels_map = {0: "‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö", 1: "‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á", 2: "‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å"}
    comments = df["comment"].astype(str).tolist()

    sentiments, confidences = [], []
    total = len(comments)
    progress_bar = st.progress(0)
    status = st.empty()

    for i in range(0, total, batch_size):
        batch = comments[i:i+batch_size]
        inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=1)
            preds = torch.argmax(probs, dim=1)
            confs = torch.max(probs, dim=1)[0]
        sentiments.extend([labels_map[p.item()] for p in preds])
        confidences.extend([c.item() for c in confs])
        progress_bar.progress((i + batch_size) / total)
        status.text(f"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {min(i + batch_size, total)} / {total} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô")

    df["sentiment"] = sentiments
    df["confidence"] = confidences
    progress_bar.empty()
    status.empty()
    return df

# ==== ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏≠‡∏õ ====
def main():
    st.sidebar.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    db_path = st.sidebar.text_input("üìÅ ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DuckDB", "./comment.duckdb")
    table_name = st.sidebar.text_input("üßæ ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á", "yt_comment_full")
    model_name = st.sidebar.selectbox("ü§ñ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•", [
        "airesearch/wangchanberta-base-att-spm",
        "airesearch/wangchanberta-base-wiki"
    ])
    batch_size = st.sidebar.slider("üì¶ Batch size", 8, 64, 32)

    df = load_data(db_path, table_name)
    if df.empty:
        st.stop()

    st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(df)} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

    if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô"):
        with st.spinner("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå..."):
            tokenizer, model = load_model(model_name)
            start = time.time()
            df_result = predict_sentiments(df, tokenizer, model, batch_size=batch_size)
            duration = time.time() - start
        st.success(f"‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô {duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

        # === ‡∏Å‡∏£‡∏≤‡∏ü ===
        st.subheader("üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å")
        fig = px.histogram(df_result, x="sentiment", color="sentiment", barmode="group")
        st.plotly_chart(fig, use_container_width=True)

        # === ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ===
        st.subheader("üìù ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
        st.dataframe(df_result[["comment", "sentiment", "confidence"]].head(20))

        # === ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ===
        st.subheader("‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
        csv = df_result.to_csv(index=False).encode("utf-8")
        st.download_button("üìÑ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV", csv, file_name="sentiment_results.csv", mime="text/csv")

if __name__ == "__main__":
    main()
