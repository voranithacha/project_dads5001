import streamlit as st
import pandas as pd
import plotly.express as px
import torch
import duckdb as db
import re
import time
from transformers import AutoTokenizer, AutoModelForSequenceClassification

st.set_page_config(page_title="‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å", layout="wide")
st.title("üîç ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô YouTube")

# ‚úÖ ‡∏¢‡πâ‡∏≤‡∏¢‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ô‡∏≠‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™ ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ cache
@st.cache_resource(show_spinner=True)
def load_model(model_name: str):
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)
    return tokenizer, model

@st.cache_data
def load_data(db_path: str, table_name: str) -> pd.DataFrame:
    try:
        con = db.connect(db_path)
        query = f"SELECT comment_text_original as comment FROM {table_name} LIMIT 1000;"
        df = con.execute(query).fetchdf()
        con.close()
        return df
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å DuckDB ‡πÑ‡∏î‡πâ: {e}")
        return pd.DataFrame()

def predict_sentiments(df, tokenizer, model, batch_size: int = 32):
    labels_map = {0: "‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö", 1: "‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á", 2: "‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å"}
    comments = df["comment"].astype(str).tolist()

    sentiments, confidences = [], []
    total = len(comments)
    progress_bar = st.progress(0)
    status = st.empty()

    for i in range(0, total, batch_size):
        batch = comments[i:i+batch_size]
        inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=1)
            preds = torch.argmax(probs, dim=1)
            confs = torch.max(probs, dim=1)[0]
        sentiments.extend([labels_map[p.item()] for p in preds])
        confidences.extend([c.item() for c in confs])
        progress_bar.progress(min((i + batch_size) / total, 1.0))
        status.text(f"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {min(i + batch_size, total)} / {total} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô")

    df["sentiment"] = sentiments
    df["confidence"] = confidences
    progress_bar.empty()
    status.empty()
    return df

def main():
    st.sidebar.header("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    db_path = st.sidebar.text_input("üìÅ ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DuckDB", "./comment.duckdb")
    table_name = st.sidebar.text_input("üßæ ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á", "yt_comment_full")
    model_name = st.sidebar.selectbox("ü§ñ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•", [
        "airesearch/wangchanberta-base-att-spm",
        "airesearch/wangchanberta-base-wiki"
    ])
    batch_size = st.sidebar.slider("üì¶ Batch size", 8, 64, 32)

    df = load_data(db_path, table_name)
    if df.empty:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏")
        st.stop()

    st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(df)} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

    if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô"):
        with st.spinner("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•..."):
            tokenizer, model = load_model(model_name)

        with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå..."):
            start = time.time()
            df_result = predict_sentiments(df, tokenizer, model, batch_size)
            duration = time.time() - start
        st.success(f"‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô {duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

        st.subheader("üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å")
        fig = px.histogram(df_result, x="sentiment", color="sentiment", barmode="group")
        st.plotly_chart(fig, use_container_width=True)

        st.subheader("üìù ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
        st.dataframe(df_result[["comment", "sentiment", "confidence"]].head(20))

        st.subheader("‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
        csv = df_result.to_csv(index=False).encode("utf-8")
        st.download_button("üìÑ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV", csv, file_name="sentiment_results.csv", mime="text/csv")

if __name__ == "__main__":
    main()
